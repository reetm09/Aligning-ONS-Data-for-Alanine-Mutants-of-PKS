{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AligningAlaToKU42Subseq\n",
    "def sam2DF(samfile, alnType):\n",
    "    with open (samfile,'r') as f:\n",
    "        #df=[x.strip().split('\\t') for x in f]\n",
    "        df =  [i.strip().split('\\t') for i in f if (i[0]!='@')] # I can do all of this in one line! Python is sooo cool\n",
    "    df = pd.DataFrame(df)\n",
    "    if(alnType == 'bbmap'):\n",
    "        #df = df[[0,2,3,9,11]]\n",
    "        #df.columns = ['gene_headers','reads','startpos','subseq','alignment_score']\n",
    "        df = df[[0,2,3,9]]\n",
    "        df.columns = ['gene_headers','reads','startpos','subseq']\n",
    "    else:\n",
    "        df = df[[0,2,3,9,11,16,17,19]]\n",
    "        df.columns = ['gene_headers','reads','startpos','subseq','alignment_score','numMismatches','MDTag','numHits']\n",
    "\n",
    "        AS = []\n",
    "        NH = []\n",
    "        for i in df['alignment_score']:\n",
    "            j = int(i[i.rfind(':')+1:])\n",
    "            AS.append(j)\n",
    "        for i in df['numHits']:\n",
    "            j = int(i[i.rfind(':')+1:])\n",
    "            NH.append(j)\n",
    "        df['AS']=AS\n",
    "        df['NH']=NH\n",
    "        df = df.sort_values(['AS','NH'],ascending = [False,True])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alignment-Copy1\n",
    "def writefrfiles(ffilename,rfilename,bcfrfilename):\n",
    "    x = open(ffilename,'w')\n",
    "    x.write(f)\n",
    "    x.close()\n",
    "    y = open(rfilename,'w')\n",
    "    y.write(r)\n",
    "    y.close()\n",
    "    z = open(bcfrfilename,'w') #both forward and reverse\n",
    "    z.write(f+r)\n",
    "    z.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alignment-Copy1\n",
    "def aligningMyself(large_string,query_string):\n",
    "    from alignment.sequence import Sequence, GAP_ELEMENT\n",
    "    from alignment.vocabulary import Vocabulary\n",
    "    from alignment.sequencealigner import SimpleScoring, LocalSequenceAligner\n",
    "    #large_string = \"AGAAGTTGATTTACGTATTGTGCTGGAGTTAATTGGCTGCAGCATTTACTATTTTCCCTTCTTACGTAAATATTTTTCTTTTAATTCCTAAATCAATCTTTTTCAATTTTTGTTTGTATTCTTTTCTTGCTTAAATCTTTAACTACAAAAACTACACATAAACTAAAAGGGACAACTTTGGCCTACAAAAAGTTGGCATGTTAGAGAACCAAAACCTGGTCTTCCTGGGTATTATAACACAAGCCAGACCTGATTTGTCTAGACGAGGAAAGAGGCCTGAGTATGAAGAGACATAGGATCATGGTGGCCAAACCCACAGAATCTTACTCTGTCCGCAGTCTGGAATGGCAACCCAACTCTTGTACAAAGTTGTCCCTGATGAGATTTCTTTCCTTTTATATTGACGACTTTTTCGTGTTTTTGTTCTCTTATAGCCGAGCTGCTTACTTATTATTATTTCACCTTCTCTTTTTATTTATACCTTATAATTATTTATTTCTTTACACTGTTACAAGAAACTCTTTTCAGAGCTGGCCCGGGTGACCGATTCGGTAATCTCCGAACAGAAGGAAGACAAGGAAGGAGCACAGACTTCAGATTGGTATATATATACTGCCTCGTGAGTGTTGAAGAAACGAAATTGCCCAGTATTCCTTAACCAACTGCACAGAACAAAACCTGCGGAAACGAAGATAAATCATGTCGAAAGCTACATACTAAGGAACGTGCTGCTGCTCATCCCTGGTCCTGTTGCCAAGCTATTTAATATCATGCACGAAAAGCAAAACAAACTTTGTGCTTCGACTGGATGTTCGTACCACCAAGGAATTACTGGAGTTAGTTGAAGCATTAGGTCCCAAAATTTGTTTACTAAAACACATGTGGATGTATGTTAATATGGACCAAAGGAGGCTTTTTGTCGACGGATCCGATATCAGTACCTTCAACAGGAAGTGTGTTACAACCGCCTTCCTATGTATGCTATACGAAGTTATGACCGAAAATCACAAACCACTTATCATGGCACCGATATCAAGTCTAATAATCCAGATCGGAAGAGCGGTTCAGCAGGAATGCCGAGACCGATCTGGCTTCGTCTTCTGCTTGACGTTCTGTTTGGCGTTTCTTGT\"\n",
    "    #large_string = \"ATCAAGAAACATAAACAGAACGTCAAGCAGGGGCGGCTGAGATCGGTCTCGGCATTCCTGCTGAACCGCTCTTCCGATCTGGATTATTGGATCTGATATCGGTGCCATGATAAGTGGTTTGTGATTTCGGATAACAACGTATAGCGTACATTATGCGGTTATGTTTCTACTTCATAGCCGGTGGTGATGTCGGATCCGTCGACAAAAACCTCCTTTGGTCCATATTAACGCCATCACATGTGTTTGGTAAACAAGTTGCAGGACCCTAAATATTCCAGCTAACTCAGTAATTCATGGTGGTACGAACATCCAGTAGGCGCACAAAGTTTGTTTTGCTTTCGTCGATATTAAATAACGCGTATGGGACTAGGATGGTAGCAGCGTTCCTTATATAACTTTCGGTACCGGTTATCTTCCGTTTCGCCTGGGGTTTTGTTCTGTGCGGTTGGTTAAGAATGCTGGGCAATTTCATTTCTTCAACTCACATGGTATATATACCAATCTGAAGTCTGTGCTCCTTCGTAGTTCTTCCTTCTGGTCGGAGATTGCCGAATCGGTCGCACGACGACTCTGAAAGGGTTCTTGTAACCAGTGTAAAGACAAATAGTATAAGGTATAAATAAAAGAAGGTGAAATAATAATAAGTAAACAGCTCGGTTATAAGAGAACAAAAACACGAAAAATCGTCAATATAAAGGAAAGAAATCGTCAGGGATAACTTTGGCGCGAGAAGAGTTGATTGCCATTCAGACTGGTGACAGGTAAGATTCTGTGGTTTGTACCCAGCAGTCATGTCTCTTCGCCTCAGGCCTCTTCCCTTGCTCAATAAGAGTGATCAGGTCTGAAGCAGAAACAATGCCAGAAGACCAGGTTTCATGGTTCTCTGTATACCAGCTTTTGTACAAAGTTGTCGCACCAGTTTAATATGTTTTTGTGGTTATGGTTAAGCGAAGAATACAAACAAAAAGTGAAAAGATTGATTTAAATTAAAGAAAATGTTGCGTGGGAAAATGGTAAATGTTTGCCGGTTAACTCCGAGCGCCCCGATCAACTGAAG\"\n",
    "    #query_string = \"GTCGACGGATCCGATATCGGTAC\"\n",
    "    #query_string = \"TAATGTATGCTATACGAAGTTA\"\n",
    "\n",
    "    #large_string = \"thelargestcityismanhattan\"\n",
    "    #query_string = \"manhattn\"\n",
    "\n",
    "    # Create sequences to be aligned.\n",
    "    a = Sequence(large_string)\n",
    "    b = Sequence(query_string)\n",
    "\n",
    "    # Create a vocabulary and encode the sequences.\n",
    "    v = Vocabulary()\n",
    "    aEncoded = v.encodeSequence(a)\n",
    "    bEncoded = v.encodeSequence(b)\n",
    "\n",
    "    # Create a scoring and align the sequences using local aligner.\n",
    "    scoring = SimpleScoring(1, -1)\n",
    "    aligner = LocalSequenceAligner(scoring, -1, minScore=5)\n",
    "    score, encodeds = aligner.align(aEncoded, bEncoded, backtrace=True)\n",
    "\n",
    "    # Iterate over optimal alignments and print them.\n",
    "    alignments = []\n",
    "    alignmentScores = []\n",
    "    alignmentPercentIdentity = []\n",
    "    indices = []\n",
    "    for encoded in encodeds:\n",
    "        alignment = v.decodeSequenceAlignment(encoded)\n",
    "\n",
    "        # Simulate a semi-local alignment.\n",
    "        if len(filter(lambda e: e != GAP_ELEMENT, alignment.second)) != len(b):\n",
    "            continue\n",
    "        if alignment.first[0] == GAP_ELEMENT or alignment.first[-1] == GAP_ELEMENT:\n",
    "            continue\n",
    "        if alignment.second[0] == GAP_ELEMENT or alignment.second[-1] == GAP_ELEMENT:\n",
    "            continue\n",
    "    \n",
    "\n",
    "        #---\n",
    "        #index = large_string.index(alignment)\n",
    "        #indices.append(index)\n",
    "        alignments.append(alignment)\n",
    "        alignmentScores.append(alignment.score)\n",
    "        alignmentPercentIdentity.append(alignment.percentIdentity())\n",
    "    \n",
    "        #---\n",
    "        #print alignment\n",
    "        #print alignment.score\n",
    "        #print alignment.percentIdentity()\n",
    "   \n",
    "    if not alignmentPercentIdentity:\n",
    "        #print 'here'\n",
    "        alignments = [(['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N'], ['A', 'T', 'A', 'T', 'C', 'G', 'G', 'T', 'A', 'C', 'C', 'T'])]\n",
    "        alignmentScores = [10]\n",
    "        alignmentPercentIdentity = [100.0]\n",
    "        #print alignments\n",
    "        #print alignmentScores\n",
    "        #print alignmentPercentIdentity\n",
    "        #print 'empty done'\n",
    "    \n",
    "    if len(alignmentPercentIdentity) == 1:\n",
    "        max_a = alignmentPercentIdentity[0]\n",
    "        #print 'alignmentPercentIdentity LENGTH 1: ', alignmentPercentIdentity\n",
    "        #print 'alignments LENGTH 1: ', alignments\n",
    "    else:\n",
    "        max_a = max(alignmentPercentIdentity)\n",
    "        \n",
    "    #print 'max_a: ',max_a\n",
    "    max_inds = [i for i, x in enumerate(alignmentPercentIdentity) if x == max_a]\n",
    "    max_s = max(alignmentScores)\n",
    "    max_scores = [i for i, x in enumerate(alignmentScores) if x == max_s] \n",
    "    #print max_inds\n",
    "    \n",
    "    #print alignmentScores\n",
    "    #print alignmentPercentIdentity\n",
    "    #print alignment\n",
    "    #print alignments[alignmentPercentIdentity.index(max(alignmentPercentIdentity))]\n",
    "    #print 'Alignment score:', alignmentScores[alignmentPercentIdentity.index(max(alignmentPercentIdentity))]\n",
    "    #print 'Percent identity:', alignmentPercentIdentity[alignmentPercentIdentity.index(max(alignmentPercentIdentity))]\n",
    "    #print alignments[1]\n",
    "    return alignments, alignmentScores, alignmentPercentIdentity, max_inds, max_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alignment-Copy1\n",
    "def getMaxPercent(alignments,alignmentScores,alignmentPercentIdentity,max_inds):\n",
    "    for i in max_inds:\n",
    "        print alignments[i]\n",
    "        print 'Alignment score:', alignmentScores[i]\n",
    "        print 'Percent identity:', alignmentPercentIdentity[i]\n",
    "        #s=\"\".join(alignments[i]).join('\\n').join('Alignment score:').join(alignmentScores[i]).join('Percent identity:').join(alignmentPercentIdentity[i]).join('\\n')\n",
    "    #return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alignment-Copy1\n",
    "def getDFwithStringMatches(alignments, max_inds, large_string):\n",
    "    #max_inds = 0\n",
    "    for r in range(0,len(alignments)):\n",
    "        t = alignments[r]\n",
    "        x = list(t[0:][:1])\n",
    "        s = \"\".join(x[0]).replace('-','')\n",
    "        newAlignments=[]\n",
    "        for i in max_inds:\n",
    "            #if len(max_inds) == 1:\n",
    "            #    print 'i',i\n",
    "            newAlignments.append(alignments[i])        \n",
    "        strlist = []\n",
    "        large_stringindices = []\n",
    "        for t in newAlignments:\n",
    "            #if len(max_inds) == 1:\n",
    "            #    print 't:',t\n",
    "            x = list(t[0:][:1])\n",
    "            s = \"\".join(x[0]).replace('-','')\n",
    "            strlist.append(s)\n",
    "            #if len(max_inds) == 1:\n",
    "                #print 'strlist:',strlist\n",
    "            if (s not in large_string):\n",
    "                index = 0\n",
    "                large_stringindices.append(index)\n",
    "            else:\n",
    "                large_stringindices.append(large_string.index(s))\n",
    "            #if len(max_inds) == 1:\n",
    "            #    print 'large_stringindices:',large_stringindices\n",
    "        df = pd.DataFrame(strlist)\n",
    "        df['indexb4bc'] = large_stringindices\n",
    "        df.columns = ['sequences','indexb4bc']\n",
    "        #if len(max_inds) == 1:\n",
    "        #        print 'df:',df\n",
    "        df = df.head(1)\n",
    "        #print 'df: ',df\n",
    "        #if len(max_inds) == 1:\n",
    "        #        print 'df.head:',df\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alignment-Copy1\n",
    "def getforalldataframe(large_string, query_string, a, mI):\n",
    "    #a,aS,aPI,mI = aligningMyself(large_string,query_string)\n",
    "    dataframe = getDFwithStringMatches(a,mI,large_string)\n",
    "    return dataframe\n",
    "#Alignment-Copy1\n",
    "def getindicesforrepeats(repeats):\n",
    "    repeats['indices'] = pd.DataFrame(range(0,len(repeats)))\n",
    "    rind = repeats.index[repeats['indexb4bc']].tolist()\n",
    "    return rind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alignment-Copy1\n",
    "def createHist(indices, start_range, end_range):\n",
    "    nums = range(start_range,end_range)\n",
    "    hist = [0]*end_range #highest quality you can have \n",
    "    for i in indices:\n",
    "        for n in nums:\n",
    "            if i==n:\n",
    "                hist[n] +=1\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alignment-Copy1\n",
    "def plottingHistogram(histogram):\n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.bar(range(0,len(histogram)),histogram)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AligningAlaToKU42\n",
    "def sam2DFWithBED(samfile, bedfile, aligner, filename):\n",
    "    with open (samfile,'r') as f:\n",
    "        #df=[x.strip().split('\\t') for x in f]\n",
    "        df =  [i.strip().split('\\t') for i in f if (i[0]!='@')] # I can do all of this in one line! Python is sooo cool\n",
    "    df = pd.DataFrame(df)\n",
    "    \n",
    "    if(aligner == 'bowtie'):\n",
    "        df = df[[0,2,3,9,11,17,18]]\n",
    "        df.columns = ['headers','read_id','startpos','seq','alignment_score','numMismatches','MDTag']\n",
    "    else:\n",
    "        df = df[[0,2,3,9,11,16,17,19]]\n",
    "        df.columns = ['headers','read_id','startpos','seq','alignment_score','numMismatches','MDTag','numHits']\n",
    "\n",
    "    with open (bedfile,'r') as f:\n",
    "        df1 = [x.strip().split('\\t') for x in f]\n",
    "    df1 = pd.DataFrame(df1)\n",
    "    df1 = df1[[5]]\n",
    "    df['strand'] = df1\n",
    "    AS = []\n",
    "    \n",
    "    for i in df['alignment_score']:\n",
    "        if i[i.rfind(':')+1:] == 'UU':\n",
    "            j = 'None'\n",
    "        else:\n",
    "            j = int(i[i.rfind(':')+1:])\n",
    "        AS.append(j)\n",
    "    df['AS']=AS\n",
    "    \n",
    "    if(aligner!='bowtie'):\n",
    "        NH = []\n",
    "        for i in df['numHits']:\n",
    "            j = int(i[i.rfind(':')+1:])\n",
    "            NH.append(j)\n",
    "        df['NH']=NH\n",
    "        df = df.sort_values(['AS','NH'],ascending = [False,True])\n",
    "    df = df.sort_values(['AS'],ascending = False)\n",
    "    df.to_csv(filename, header=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desktop/sort_out_later/Figure_it_out/This_is_it./Current/Genomics/Jupyter/Course4/Week1/hw1_naive_with_rc.ipynb\n",
    "def reverseComplement(s):\n",
    "    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N'}\n",
    "    t = ''\n",
    "    for base in s:\n",
    "        t = complement[base] + t\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desktop/GRIPS/NanoporeSeqAnalysis/Functions.ipynb\n",
    "#ConstantSequenceFandR\n",
    "def seqCounter(beforeBC, index):\n",
    "    t = 0; c= 0; g = 0; a = 0;\n",
    "    x = []\n",
    "    for i in beforeBC:\n",
    "        if (i!= ''):\n",
    "            if (i[index]==\"T\"):\n",
    "                t = t+1\n",
    "            elif (i[index]==\"C\"):\n",
    "                c = c+1\n",
    "            elif (i[index]==\"G\"):\n",
    "                g = g+1\n",
    "            else:\n",
    "                a = a+1\n",
    "    #print 'Count: ',index,'----------------------------'\n",
    "    #print 'T: ',t,' C: ', c, ' G: ',g,' A: ',a\n",
    "    x.append(t)\n",
    "    x.append(c)\n",
    "    x.append(g)\n",
    "    x.append(a)\n",
    "    return x\n",
    "def maxLetter(x):\n",
    "    index = x.index(max(x))\n",
    "    seq = ''\n",
    "    if (index == 0):\n",
    "        l = 'T'\n",
    "    elif (index == 1):\n",
    "        l = 'C'\n",
    "    elif (index == 2):\n",
    "        l = 'G'\n",
    "    else:\n",
    "        l = 'A'\n",
    "    seq = seq + l\n",
    "    #print seq\n",
    "    return seq\n",
    "def seqGenerator(beforeBC):\n",
    "    s = ''\n",
    "    r = []\n",
    "    for i in range(0,len(beforeBC[0])):\n",
    "        r = seqCounter(beforeBC,i)\n",
    "        s = s + maxLetter(r)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desktop/GRIPS/NanoporeSeqAnalysis/Functions.ipynb\n",
    "#ConstantSequenceFandR\n",
    "def creatingSeqbeforeBC(df1, seqsname,startposname,length):\n",
    "    beforeBC = []\n",
    "    count = 0\n",
    "    s =''\n",
    "    for i in df1[seqsname]:\n",
    "        index = df1[startposname][count]-length\n",
    "        s = i[index:index+length+1]\n",
    "        beforeBC.append(s)\n",
    "        count = count + 1\n",
    "    return beforeBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desktop/GRIPS/NanoporeSeqAnalysis/Functions.ipynb\n",
    "#ConstantSequenceFandR\n",
    "def makingConstant(seqs,start,end,query_string):\n",
    "    #query_string = 'TATAATGTATGCTATACGAAGTTAT'\n",
    "    d1 = pd.DataFrame()\n",
    "    #for i in seqs[:10]:\n",
    "    count = 0\n",
    "    for i in seqs[start:end]:\n",
    "    #for i in seqs:\n",
    "        large_string = i\n",
    "        #print len(large_string)\n",
    "        a, aS,aPI, mI, mS = aligningMyself(large_string, query_string)\n",
    "        #d = getforalldataframe(large_string, query_string, a, mI)\n",
    "        d = getDFwithStringMatches(a,mS,large_string)\n",
    "        #print 'done'\n",
    "        #print 'count: ', count\n",
    "        #print 'dataframe: ', d\n",
    "        #print 'makingConstant done'\n",
    "        d1 = d1.append(d)        \n",
    "        d1 = d1.reset_index(drop = True)\n",
    "        #if(large_string == seqs[24] or large_string == seqs[25]):\n",
    "         #   print a\n",
    "         #   print aS\n",
    "         #   print aPI\n",
    "         #   print mI\n",
    "         #   print len(mI)\n",
    "         #   print d\n",
    "         #   print d1\n",
    "        count = count + 1\n",
    "    return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desktop/GRIPS/NanoporeSeqAnalysis/Functions.ipynb\n",
    "#ConstantSequenceFandR\n",
    "def dfBarcodeAln10000(d1, seqs, num, typeBC):\n",
    "    reads = []\n",
    "    barcodeAln = []\n",
    "    barcodes = []\n",
    "    count = 0\n",
    "    headers = []\n",
    "    indexb4bcEND = []\n",
    "    r = 0\n",
    "    for i in d1['indexb4bc']: \n",
    "        lengthConstantSeq = len(d1['sequences'][count])\n",
    "        if(len(seqs[count])>=num):\n",
    "            if(i-226 <= 0):\n",
    "                reads.append(seqs[count][:i+lengthConstantSeq+226])\n",
    "                #if(count ==55):\n",
    "                    #print 'if than 650: ',count\n",
    "            elif(i+len(d1['sequences'][count])+226 >= len(seqs[count])):\n",
    "                reads.append(seqs[count][i-226:])\n",
    "                #if(count ==55):\n",
    "                    #print 'elif than 650: ',count,i, 'total len', len(seqs[count])\n",
    "            else:\n",
    "                reads.append(seqs[count][i-226:i+lengthConstantSeq+226])\n",
    "                #if(count ==55):\n",
    "                    #print 'else than 650: ',count\n",
    "            #print 'greater', str(count)\n",
    "            \n",
    "        else:\n",
    "            reads.append(seqs[count][0:])\n",
    "            #print 'less', str(count)\n",
    "        if(typeBC == 'after'):    \n",
    "            barcodeAln.append(i-len(d1['sequences'][count]))\n",
    "        elif(typeBC=='before'):\n",
    "            barcodeAln.append(i+len(d1['sequences'][count]))\n",
    "        else: #REDI\n",
    "            barcodeAln.append(i-len(d1['sequences'][count]))\n",
    "        count = count + 1\n",
    "    d1['reads']=reads\n",
    "    d1[typeBC+'barcodeAln']=barcodeAln\n",
    "    #d1['barcode']=barcodes\n",
    "    #d1['headers'] = headers\n",
    "    return d1\n",
    "def dfBarcodeAln10000_gene(d1, seqs, num, typeBC):\n",
    "    reads = []\n",
    "    barcodeAln = []\n",
    "    barcodes = []\n",
    "    count = 0\n",
    "    headers = []\n",
    "    indexb4bcEND = []\n",
    "    r = 0\n",
    "    l = 1000\n",
    "    for i in d1['indexb4bc']: \n",
    "        lengthConstantSeq = len(d1['sequences'][count])\n",
    "        if(len(seqs[count])>=num):\n",
    "            if(i-l <= 0):\n",
    "                reads.append(seqs[count][:i+lengthConstantSeq+l])\n",
    "                #if(count ==55):\n",
    "                    #print 'if than 650: ',count\n",
    "            elif(i+len(d1['sequences'][count])+l >= len(seqs[count])):\n",
    "                reads.append(seqs[count][i-l:])\n",
    "                #if(count ==55):\n",
    "                    #print 'elif than 650: ',count,i, 'total len', len(seqs[count])\n",
    "            else:\n",
    "                reads.append(seqs[count][i-l:i+lengthConstantSeq+l])\n",
    "                #if(count ==55):\n",
    "                    #print 'else than 650: ',count\n",
    "            #print 'greater', str(count)\n",
    "            \n",
    "        else:\n",
    "            reads.append(seqs[count][0:])\n",
    "            #print 'less', str(count)\n",
    "        if(typeBC == 'after'):    \n",
    "            barcodeAln.append(i-len(d1['sequences'][count]))\n",
    "        elif(typeBC=='before'):\n",
    "            barcodeAln.append(i+len(d1['sequences'][count]))\n",
    "        else: #REDI\n",
    "            barcodeAln.append(i-len(d1['sequences'][count]))\n",
    "        count = count + 1\n",
    "    d1['reads']=reads\n",
    "    d1[typeBC+'barcodeAln']=barcodeAln\n",
    "    #d1['barcode']=barcodes\n",
    "    #d1['headers'] = headers\n",
    "    return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ConstantSequenceFandR\n",
    "def creatingDFBarcodeAln(d1, seqs, df1):\n",
    "    reads = []\n",
    "    barcodeAln = []\n",
    "    barcodes = []\n",
    "    count = 0\n",
    "    headers = []\n",
    "    indexb4bcEND = []\n",
    "    r = 0\n",
    "    for i in d1['indexb4bc']:\n",
    "        #print count\n",
    "        #--added\n",
    "        #print i\n",
    "        if(i <= df1['startpos'][count]):\n",
    "            r = i\n",
    "            x = df1['endpos'][count]\n",
    "        else:\n",
    "            r = df1['startpos'][count]\n",
    "            x = i+len(d1['sequences'][count])\n",
    "        #print 'r: ',r,'x: ',x\n",
    "        reads.append(seqs[count][r:x])\n",
    "        #--\n",
    "       # reads.append(seqs[count][i:i+len(d1['sequences'][count])+26])\n",
    "        barcodeAln.append(i+len(d1['sequences'][count]))\n",
    "        barcodes.append(df1['barcodes'][count])\n",
    "        headers.append(df1['headers'][count])\n",
    "        count = count + 1\n",
    "    d1['reads']=reads\n",
    "    d1['barcodeAln']=barcodeAln\n",
    "    d1['barcode']=barcodes\n",
    "    d1['headers'] = headers\n",
    "    return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desktop/GRIPS/NanoporeSeqAnalysis/Functions.ipynb\n",
    "#ConstantSequenceFandR\n",
    "def plottingError(r, df1, d1):\n",
    "    #r = len(d1) \n",
    "    y1 = df1['startpos'][:r]\n",
    "    y2 = d1['barcodeAln']\n",
    "    y3 = y1-y2\n",
    "\n",
    "    df=pd.DataFrame({'x': range(0,r), 'orginalPos': y1, 'constantPos': y2, 'total error':y3})\n",
    "    #plt.plot( 'x', 'orginalPos', data=df, marker='o', markerfacecolor='blue', markersize=8, color='skyblue', linewidth=2)\n",
    "    #plt.plot( 'x', 'constantPos', data=df, marker='o', color='olive', linewidth=2)\n",
    "    plt.plot('x','total error', data = df, marker = 'o', color = 'red', linewidth =1)\n",
    "    plt.legend()\n",
    "    return y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desktop/GRIPS/NanoporeSeqAnalysis/Functions.ipynb\n",
    "#ConstantSequenceFandR\n",
    "def printingPercentDifferent(y3):\n",
    "    count = 0\n",
    "    for i in y3:\n",
    "        if abs(i) > 200: #using 200 so that the read length is 19+26+200 ~250bp which is ok length for tophat\n",
    "            count = count+1\n",
    "    print 'Percent different: ',str((float(count)/len(y3))*100) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desktop/GRIPS/NanoporeSeqAnalysis/BarcodeAndReadsTogether.ipynb\n",
    "def readAlignedDF(txtfilename, csvfilename):\n",
    "    csv_file = txttocsv(txtfilename, csvfilename)\n",
    "    df = pd.read_csv(csvfilename, header = None)\n",
    "    df.columns = ['headers', 'startpos', 'endpos', 'barcodeNum', 'strand']\n",
    "    return df\n",
    "#Desktop/GRIPS/NanoporeSeqAnalysis/BarcodeAndReadsTogether.ipynb\n",
    "def gettingBarcodeandSeqs(df, seqsdf):\n",
    "    df1 = pd.merge(df, seqsdf, on='headers', how='left') #how  = 'left'\n",
    "    df1 = df1.dropna()\n",
    "    df1 = df1.sort_values('barcodeNum')\n",
    "    df1 = df1.reset_index(drop = True)\n",
    "    return df1 #even after allowing 4 mismatches, it is 8904, but there are a lot more sequences that align to barcode 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desktop/GRIPS/NanoporeSeqAnalysis/ReadingPassFasta.ipynb\n",
    "def passfastadf(fastafilename):\n",
    "    sequences = []\n",
    "    names = []\n",
    "    with open(fastafilename, 'r') as f:\n",
    "            for line in f:\n",
    "                #print line\n",
    "                if not line[0] == '>':\n",
    "                    sequences.append(line.rstrip().upper())\n",
    "                else: \n",
    "                    header = line.split(\">\",1)[1]\n",
    "                    names.append(header.split(\" \",1)[0])\n",
    "    df = pd.DataFrame({'headers':names})\n",
    "    df['seqs'] = sequences\n",
    "    return df\n",
    "#Desktop/GRIPS/NanoporeSeqAnalysis/ReadingPassFasta.ipynb\n",
    "def txttocsv(txt,blankcsv):\n",
    "    import csv\n",
    "\n",
    "    #txt_file = r\"tophat2converted_out/accepted_hits.txt\"\n",
    "    #csv_file = r\"tophat2converted_out/accepted_hits.csv\"\n",
    "    txt_file = txt\n",
    "    csv_file = blankcsv\n",
    "    # use 'with' if the program isn't going to immediately terminate\n",
    "    # so you don't leave files open\n",
    "    # the 'b' is necessary on Windows\n",
    "    # it prevents \\x1a, Ctrl-z, from ending the stream prematurely\n",
    "    # and also stops Python converting to / from different line terminators\n",
    "    # On other platforms, it has no effect\n",
    "    in_txt = csv.reader(open(txt_file, \"rb\"), delimiter = '\\t')\n",
    "    out_csv = csv.writer(open(csv_file, 'wb'))\n",
    "\n",
    "    csv_file = out_csv.writerows(in_txt)\n",
    "    return csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desktop/GRIPS/NanoporeSeqAnalysis/CreatingMasterFrame.ipynb\n",
    "def creatingMasterFrame(filename): #tab separated file\n",
    "    forwardSeq = ''\n",
    "    reverseSeq = ''\n",
    "    with open(filename,'r') as f:\n",
    "        df=[x.strip().split('\\t') for x in f]\n",
    "    df = pd.DataFrame(df)\n",
    "    new_header = df.iloc[0] #grab the first row for the header\n",
    "    df = df[1:] #take the data less the header row\n",
    "    df.columns = new_header\n",
    "    x = 0\n",
    "    pos = []\n",
    "    for i in df['BC.Read.1']:\n",
    "        pos.append(x)\n",
    "        x = x+len(i)\n",
    "    df.loc[:,'posSeq'] = pd.Series(pos, index=df.index) \n",
    "    count = 0\n",
    "    for i in df['BC.Read.1']:\n",
    "        #forwardSeq = forwardSeq+\"\\n\"+\">f\"+str(count)+\"\\n\"+i\n",
    "        forwardSeq = forwardSeq+\"\\n\"+\">\"+str(count)+\"\\n\"+i\n",
    "        count = count+1\n",
    "    count = 0\n",
    "    for i in df['BC.Read.2']:\n",
    "        reverseSeq = reverseSeq+\"\\n\"+\">r\"+str(count)+\"\\n\"+i\n",
    "        count = count+1\n",
    "    return df, forwardSeq, reverseSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desktop/GRIPS/NanoporeSeqAnalysis/ORFGenesToBarcodes.ipynb\n",
    "def addingBarcodestoDf(mainDF, df1): #mainDF is dataframe with original barcodes while df1 is dataframe with reads aligned\n",
    "    barcodes = []\n",
    "    for i in range(0, len(df1)):\n",
    "        x = df1['barcodeNum'][i]+1\n",
    "        if df1['strand'][i] == '+':\n",
    "            r = mainDF['BC.Read.1'][x]\n",
    "        else:\n",
    "            r = mainDF['BC.Read.2'][x]\n",
    "        barcodes.append(r)\n",
    "        \n",
    "    df1['barcodes'] = barcodes\n",
    "    return df1\n",
    "\n",
    "#Desktop/GRIPS/NanoporeSeqAnalysis/ORFGenesToBarcodes.ipynb\n",
    "def writingReadsFasta(df1, filename):\n",
    "    fastalist = []\n",
    "    r = ''\n",
    "    for i in range(0,len(df1)):\n",
    "        s = '>'+str(df1['headers'][i])+' '+'BC:'+str(df1['barcodeNum'][i])\n",
    "        #s = s+'\\n'+df1['seqs'][i] +'\\n'\n",
    "        fastalist.append(s)\n",
    "    for j in fastalist:\n",
    "        r = r+j\n",
    "    #x = open(filename, 'w')\n",
    "    #x.write(r)\n",
    "    #x.close()\n",
    "    \n",
    "#Desktop/GRIPS/NanoporeSeqAnalysis/ORFGenesToBarcodes.ipynb\n",
    "def txtwriterfromcsv():\n",
    "    import csv\n",
    "    csv_file = raw_input('Enter the name of your input file: ')\n",
    "    txt_file = raw_input('Enter the name of your output file: ')\n",
    "    with open(txt_file, \"w\") as my_output_file:\n",
    "        with open(csv_file, \"r\") as my_input_file:\n",
    "            [ my_output_file.write(\" \".join(row)+'\\n') for row in csv.reader(my_input_file)]\n",
    "        my_output_file.close()\n",
    "        \n",
    "#Desktop/GRIPS/NanoporeSeqAnalysis/ORFGenesToBarcodes.ipynb\n",
    "def writingFASTQORFgenes(df, filename, seqsname):\n",
    "    fqlist = []\n",
    "    s = ''\n",
    "    r = ''\n",
    "    for i in range(0,len(df)):\n",
    "        #s = '@'+df['header'][i]+df['read_seq'][i]+'\\n'+'+'+'\\n'+('I'*len(df['read_seq'][i]))+'\\n'\n",
    "        s = '@'+str(df['headers'][i])+' '+'BC:'+str(df1['barcodeNum'][i])+'\\n'+df[seqsname][i]+'\\n'+'+'+'\\n'+('I'*len(df[seqsname][i]))+'\\n'\n",
    "        fqlist.append(s)\n",
    "    #print fqlist\n",
    "    for j in fqlist:\n",
    "        r = r+j\n",
    "    #print r\n",
    "    writeFile(filename,r)\n",
    "    \n",
    "#Desktop/GRIPS/NanoporeSeqAnalysis/ORFGenesToBarcodes.ipynb\n",
    "def writeFile(filename, stringtowrite):\n",
    "    x = open(filename, 'w')\n",
    "    x.write(stringtowrite)\n",
    "    x.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desktop/GRIPS/NanoporeSeqAnalysis/CreatingORFFrame.ipynb\n",
    "def readGenome(filename):\n",
    "    genome = ''\n",
    "    geneid = []\n",
    "    x = []\n",
    "    maxLen = 0\n",
    "    counter = 0\n",
    "    bcnum = []\n",
    "    indEndSeq = []\n",
    "    readSeq = []\n",
    "    lines = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            if not line[0] == '>':\n",
    "                genome += line.rstrip()\n",
    "                indEndSeq.append(len(line.rstrip()))\n",
    "                readSeq.append(line.rstrip().upper())\n",
    "            else: \n",
    "                counter+=1\n",
    "                x.append(len(line))\n",
    "                lines.append(line[1:-1])\n",
    "                y = line.index(\"GENE_ID: \")\n",
    "                r = line[y + len(\"GENE_ID: \"):-1]\n",
    "                if r == \"NA\": #all gene_id's that are NA are now equal to 0\n",
    "                    r =0\n",
    "                geneid.append(int(r))\n",
    "                bc = line.index(\"BC_NUM: \") + len(\"BC_NUM: \")\n",
    "                s = line[bc:y-1]\n",
    "                bcnum.append(s.split(\",\"))\n",
    "        d = {'bc_num':pd.Series(bcnum, index = range(0,15483)),\n",
    "             'gene_id':pd.Series(geneid, index = range(0,15483)),\n",
    "             'read_seq':pd.Series(readSeq, index = range(0,15483)),\n",
    "            'header':pd.Series(lines, index = range(0,15483))}\n",
    "        df = pd.DataFrame(d)\n",
    "    return genome,x,df #genome, lineLengths, and dataframe from dictionary\n",
    "\n",
    "#Desktop/GRIPS/NanoporeSeqAnalysis/CreatingORFFrame.ipynb\n",
    "def creatingInputFrame(df):\n",
    "    counter = 0\n",
    "    for i in df['bc_num']: #getting indices of where there is a list of bc_num\n",
    "        if (len(i)>1):\n",
    "            df = df.append([df.loc[[counter]]]*(len(i)-1))\n",
    "        counter = counter +1 \n",
    "    df = df.sort_values(by=['gene_id'])\n",
    "    df = df.reset_index(drop = True)\n",
    "    count =0\n",
    "    l=0\n",
    "    for i in df['gene_id']: \n",
    "        if(count == len(df['gene_id'])-1):\n",
    "            if(df['gene_id'][count] == df['gene_id'][count-1]):\n",
    "                if(l>=len(df['bc_num'][count])):\n",
    "                         l=0\n",
    "                df.loc[count,'bc_num'] = df['bc_num'][count][l]\n",
    "                l = l+1\n",
    "        elif(count < len(df['gene_id'])):\n",
    "            if(df['gene_id'][count] == df['gene_id'][count+1]):\n",
    "                if(df['gene_id'][count]==i):\n",
    "                    if(l>=len(df['bc_num'][count])):\n",
    "                         l=0\n",
    "                    df.loc[count,'bc_num'] = df['bc_num'][count][l]\n",
    "                    l = l+1\n",
    "            elif(df['gene_id'][count]==df['gene_id'][count-1]):\n",
    "                if(df['gene_id'][count]==i):\n",
    "                    if(l>=len(df['bc_num'][count])):\n",
    "                         l=0\n",
    "                    df.loc[count,'bc_num'] = df['bc_num'][count][l]\n",
    "                    l = l+1\n",
    "            else:\n",
    "                l=0\n",
    "        count = count +1\n",
    "    return df\n",
    "\n",
    "#Desktop/GRIPS/NanoporeSeqAnalysis/CreatingORFFrame.ipynb\n",
    "def createHistORF(indices):\n",
    "    nums = range(25,100)\n",
    "    hist = [0]*100 #highest quality you can have \n",
    "    for i in indices:\n",
    "        for n in nums:\n",
    "            if i==n:\n",
    "                hist[n] +=1\n",
    "    return hist\n",
    "\n",
    "#Desktop/GRIPS/NanoporeSeqAnalysis/CreatingORFFrame.ipynb\n",
    "def plottingHistogramORF(histogram):\n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.bar(range(0,len(histogram)),histogram)\n",
    "    plt.show()\n",
    "\n",
    "#Desktop/GRIPS/NanoporeSeqAnalysis/CreatingORFFrame.ipynb    \n",
    "def writingORFFASTQ(df, filename):\n",
    "    fqlist = []\n",
    "    s = ''\n",
    "    r = ''\n",
    "    for i in range(0,len(df)):\n",
    "        #s = '@'+df['header'][i]+df['read_seq'][i]+'\\n'+'+'+'\\n'+('I'*len(df['read_seq'][i]))+'\\n'\n",
    "        s = '@'+str(df['gene_id'][i])+'\\n'+df['read_seq'][i]+'\\n'+'+'+'\\n'+('I'*len(df['read_seq'][i]))+'\\n'\n",
    "        fqlist.append(s)\n",
    "    #print fqlist\n",
    "    for j in fqlist:\n",
    "        r = r+j\n",
    "    #print r\n",
    "    writeFile(filename,r)\n",
    "\n",
    "#Desktop/GRIPS/NanoporeSeqAnalysis/CreatingORFFrame.ipynb    \n",
    "def writeFileORF(filename, stringtowrite):\n",
    "    x = open(filename, 'w')\n",
    "    x.write(stringtowrite)\n",
    "    x.close()\n",
    "    \n",
    "#Desktop/GRIPS/NanoporeSeqAnalysis/CreatingORFFrame.ipynb\n",
    "def writingReadsFastaORF(df, filename):\n",
    "    fastalist = []\n",
    "    r = ''\n",
    "    for i in range(0,len(df)):\n",
    "        s = '>'+str(df['header'][i])\n",
    "        s = s + '\\t'\n",
    "        #s = s+'\\n'+df1['seqs'][i] +'\\n'\n",
    "        fastalist.append(s)\n",
    "    for j in fastalist:\n",
    "        r = r+j\n",
    "    #x = open(filename, 'w')\n",
    "    #x.write(r)\n",
    "    #x.close()\n",
    "    \n",
    "#Desktop/GRIPS/NanoporeSeqAnalysis/CreatingORFFrame.ipynb\n",
    "def csv_to_txt(csv_file,txt_file):\n",
    "    import csv\n",
    "    #csv_file = raw_input('Enter the name of your input file: ')\n",
    "    #txt_file = raw_input('Enter the name of your output file: ')\n",
    "    with open(txt_file, \"w\") as my_output_file:\n",
    "        with open(csv_file, \"r\") as my_input_file:\n",
    "            [ my_output_file.write(\" \".join(row)+'\\n') for row in csv.reader(my_input_file)]\n",
    "        my_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AllBarcodesDataframe\n",
    "def creatingAllBCdf(filename):\n",
    "    with open(filename,'r') as f:\n",
    "        df=[x.strip().split('\\t') for x in f]\n",
    "    df = pd.DataFrame(df)\n",
    "    new_header = df.iloc[0] #grab the first row for the header\n",
    "    df = df[1:] #take the data less the header row\n",
    "    df.columns = new_header\n",
    "    return df\n",
    "#AllBarcodesDataframe\n",
    "def mainDFandAllBC(df, mainDF):\n",
    "    mainDF = mainDF.reset_index(drop = True)\n",
    "    mainDF1 = pd.concat([mainDF]*12)\n",
    "    df1 = pd.DataFrame()\n",
    "    df1 = pd.concat([df]*1536)\n",
    "    df1 = df1.sort_values('Plate')\n",
    "    df1 = df1.sort_index(axis = 0)\n",
    "    df1 = df1.reset_index(drop = True)\n",
    "    mainDF1 = mainDF1.reset_index(drop = True)\n",
    "    mainDF1['PLATE'] = df1['Plate']\n",
    "    mainDF1['FWD PLATE BC'] = df1['FWD PLATE BC']\n",
    "    mainDF1['REV PLATE BC'] = df1['REV PLATE BC']\n",
    "    return mainDF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constantSeqBenchling\n",
    "def maxLineLen(df,columnName):\n",
    "    lineLen = []\n",
    "    for i in df[columnName]:\n",
    "        lineLen.append(len(i))\n",
    "    return lineLen, max(lineLen)\n",
    "def maxLineLenList(list1):\n",
    "    lineLen = []\n",
    "    for i in list1:\n",
    "        lineLen.append(len(i))\n",
    "    return lineLen, max(lineLen), lineLen.index(max(lineLen))\n",
    "\n",
    "#constantSeqBenchling\n",
    "def determiningAlignment(constantSeq, allseqs, start, end, cutOffNum ,typeBC, gene, shortRead_len, version, read_ids):\n",
    "    \n",
    "    query_string = constantSeq\n",
    "    d10 = makingConstant(allseqs,start,end,query_string)\n",
    "    d1 = pd.DataFrame()\n",
    "    frames = [d10]\n",
    "    d1 = pd.concat(frames)\n",
    "    d1 = d1.reset_index(drop = 'true')\n",
    "    \n",
    "    if (gene == True):\n",
    "        d1 = dfBarcodeAln10000_gene(d1,allseqs,cutOffNum,typeBC)\n",
    "    else:\n",
    "        #d1 = dfBarcodeAln10000(d1,allseqs,cutOffNum,typeBC)\n",
    "        d1 = dfBarcodeAln_new(d1, allseqs, cutOffNum, shortRead_len, typeBC )\n",
    "    if(version == 'First'):\n",
    "        d1['read_id'] =  read_ids\n",
    "    else:\n",
    "        d1['read_id'] = read_ids #list\n",
    "    df = d1[['read_id','reads']]\n",
    "    return d1, df\n",
    "\n",
    "#constantSeqBenchling\n",
    "def writingTxtForCSB(df,csvfile,txtfile): #CSB: ConstantSeqBenchling\n",
    "    df.to_csv(csvfile,sep='\\t',index=False,header = False)\n",
    "    csv_to_txt(csvfile,txtfile)\n",
    "    \n",
    "#constantSeqBenchling\n",
    "def gettingNecessaryDuplicates(fbcd1, fbcsamdf3, num): #getting only those reads in which alignment of barcode is closest to constant sequence\n",
    "    needed = []\n",
    "    duplicates = []\n",
    "    numD = 0\n",
    "    row = []\n",
    "    compare2Ind = 0\n",
    "    ind = 0\n",
    "    #num = int(num)\n",
    "    #getting compare2Ind number\n",
    "    #print num\n",
    "    #print int(num)\n",
    "    #print type(num)\n",
    "    #print fbcd1['indexb4bc']\n",
    "    counter = 0\n",
    "    for i in fbcd1['read_id']:\n",
    "        if i == num:\n",
    "            ind = counter\n",
    "        counter = counter+1\n",
    "    compare2Ind= fbcd1['indexb4bc'][ind]\n",
    "    #print compare2Ind\n",
    "    #compare2Ind = fbcd1['read_id'][num]\n",
    "    #print 'compare2Ind',compare2Ind\n",
    "    #print type(num)\n",
    "    #print fbcd1['sequences'][0]\n",
    "    #print fbcd1['reads'][0]\n",
    "    #compare2Ind = fbcd1['reads'][int(num)].index(str(fbcd1['sequences'][int(num)])) # DO THIS\n",
    "    \n",
    "    #in the past------ #this made it extremely slow, 15secs per run, now I made it faster too\n",
    "    #for i in fbcsamdf3['reads']:\n",
    "    #    x = fbcd1['indexb4bc'][int(num)]\n",
    "    #    print 'i: ',i\n",
    "    #    print 'x: ',x\n",
    "    #    print 'num: ',num\n",
    "    #    print 'fbcd1: ', fbcd1\n",
    "    #    compare2Ind = fbcd1.iloc[int(i)][4] #compare to index\n",
    "    #-------------------\n",
    "    #getting duplicates\n",
    "    count = 0\n",
    "    for i in fbcsamdf3['reads']:\n",
    "        if (int(i) == num):\n",
    "            duplicates.append(int(fbcsamdf3.iloc[count][2]))\n",
    "            row.append(fbcsamdf3.iloc[count])\n",
    "            numD = numD + 1\n",
    "        count = count+1\n",
    "    duplicates.sort()\n",
    "    closestInd = takeClosest(duplicates, compare2Ind)\n",
    "    indices = []\n",
    "    for i in row:\n",
    "        if int(i[2])==closestInd:\n",
    "            indices.append(i)\n",
    "    needed.append(int(indices[0].name))\n",
    "    count = 0\n",
    "    ind = 0\n",
    "    for i in fbcsamdf3.index:\n",
    "        if i == needed[0]:\n",
    "            #print i\n",
    "            ind = count\n",
    "        count = count +1\n",
    "    return fbcsamdf3[ind:ind+1]\n",
    "#example of using gettingNecessaryDuplicates\n",
    "#randomd1 = gettingNecessaryDuplicates(fbcd1, fbcsamdf3, 9290)\n",
    "#randomd2 = gettingNecessaryDuplicates(fbcd1, fbcsamdf3, 414)\n",
    "#frames = [randomd1,randomd2]\n",
    "#random = pd.concat(frames, sort = False)\n",
    "#random\n",
    "\n",
    "#constantSeqBenchling\n",
    "def gettingNecessaryDuplicatesForAll(fbcd1,fbcsamdf, dropsamdf):\n",
    "    frames = []\n",
    "    for i in dropsamdf['reads']: #changed from fbcsamdf to dropsamdf because it will still work since it only has unique 'reads'\n",
    "        if i != '*':\n",
    "            d = gettingNecessaryDuplicates(fbcd1, fbcsamdf, int(i))\n",
    "            frames.append(d)\n",
    "    df = pd.concat(frames,sort = False)\n",
    "    return df\n",
    "\n",
    "#constantSeqBenchling\n",
    "#https://codereview.stackexchange.com/questions/190145/find-the-closest-number-in-a-sorted-list-to-a-given-target-number\n",
    "#slower than takeClosest()\n",
    "def get_closest_value(arr, target):\n",
    "    n = len(arr)\n",
    "    left = 0\n",
    "    right = n - 1\n",
    "    mid = 0\n",
    "    #print ('right',right)\n",
    "    # edge case - last or above all\n",
    "    if target >= arr[n - 1]:\n",
    "        #print 'target1', target\n",
    "        return arr[n - 1]\n",
    "    # edge case - first or below all\n",
    "    if target <= arr[0]:\n",
    "        #print 'target2', target\n",
    "        return arr[0]\n",
    "    # BSearch solution: Time & Space: Log(N)\n",
    "\n",
    "    while left < right:\n",
    "        mid = (left + right) // 2  # find the mid\n",
    "        if target < arr[mid]:\n",
    "            right = mid\n",
    "        elif target > arr[mid]:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            return arr[mid]\n",
    "\n",
    "    if target < arr[mid]:\n",
    "        return find_closest(arr[mid - 1], arr[mid], target)\n",
    "    else:\n",
    "        return find_closest(arr[mid], arr[mid + 1], target)\n",
    "\n",
    "# findClosest\n",
    "# We find the closest by taking the difference\n",
    "# between the target and both values. It assumes\n",
    "# that val2 is greater than val1 and target lies\n",
    "# between these two. \n",
    "def find_closest(val1, val2, target):\n",
    "    return val2 if target - val1 >= val2 - target else val1\n",
    "\n",
    "#constantSeqBenchling\n",
    "#https://stackoverflow.com/questions/12141150/from-list-of-integers-get-number-closest-to-a-given-value\n",
    "#faster than get_closest_value()\n",
    "def takeClosest(myList, myNumber):\n",
    "    from bisect import bisect_left\n",
    "    \"\"\"\n",
    "    Assumes myList is sorted. Returns closest value to myNumber.\n",
    "\n",
    "    If two numbers are equally close, return the smallest number.\n",
    "    \"\"\"\n",
    "    pos = bisect_left(myList, myNumber)\n",
    "    #print 'myList:',myList\n",
    "    #print 'myList length',len(myList)\n",
    "    #print 'Position',pos\n",
    "    #print 'myNumber', myNumber\n",
    "    if pos == 0:\n",
    "        #print 'myList[0]',myList[0]\n",
    "        return myList[0]\n",
    "    if pos == len(myList):\n",
    "        return myList[-1]\n",
    "    before = myList[pos - 1]\n",
    "    after = myList[pos]\n",
    "    if after - myNumber < myNumber - before:\n",
    "        return after\n",
    "    else:\n",
    "        return before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CheckingAlignment\n",
    "def checkingAlignment(gene_headersList, samBedDF, headerColName):\n",
    "    indices = samBedDF[samBedDF[headerColName].isin(gene_headersList)].index.tolist()\n",
    "    df1 = pd.DataFrame()\n",
    "    df1 = samBedDF[samBedDF[headerColName].isin(gene_headersList)]\n",
    "    if df1.empty:\n",
    "        successful = False\n",
    "    else:\n",
    "        successful = True\n",
    "    return df1,indices, successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ConstantSeqBenchlingApplication\n",
    "def removeStarredReads(samdf10):\n",
    "    df = pd.DataFrame\n",
    "    df = samdf10[samdf10['read_id'] != '*']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histograms\n",
    "def gettingReadLens(seqs):\n",
    "    lineLenSeqs = []\n",
    "    for i in seqs:\n",
    "        lineLenSeqs.append(len(i))\n",
    "    return lineLenSeqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KU42_donors.ipynb\n",
    "def ku42df(filename):\n",
    "    with open(filename,'r') as f:\n",
    "        df=[x.strip().split('\\t') for x in f]\n",
    "    df = pd.DataFrame(df)\n",
    "    new_header = df.iloc[0] #grab the first row for the header\n",
    "    df = df[1:] #take the data less the header row\n",
    "    df.columns = new_header\n",
    "    headers = []\n",
    "    for x in df.columns:\n",
    "        headers.append(x.lower().title())\n",
    "    df.columns = headers\n",
    "    df = df.reset_index(drop = 'true')\n",
    "    j = []\n",
    "    for i in df['Name']:\n",
    "        if i.startswith('\"') and i.endswith('\"'):\n",
    "            i = i[1:-1]\n",
    "        j.append(i)\n",
    "    df['Name'] = j\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ConstantSequenceBenchlingREDI\n",
    "#getting entire reads from the matched reads\n",
    "def gettingMatchedSeqs(bcd2165, readName, seqsdf, seqsdfName, headerName, typeBC, choiceSeqName, choiceSeqHeader):\n",
    "    bcd2165_readNum = bcd2165[[readName]]\n",
    "    sequences = []\n",
    "    readNum = []\n",
    "    seqchoice = []\n",
    "    for j in bcd2165_readNum[readName]:\n",
    "        sequences.append(seqsdf[seqsdfName].iloc[int(j)])\n",
    "        readNum.append(j)\n",
    "        seqchoice.append(seqsdf[choiceSeqName].iloc[int(j)])\n",
    "    bcd2165_totalReads = pd.DataFrame({typeBC: bcd2165[headerName].tolist(),'read_id': readNum, 'entire_read':sequences, choiceSeqHeader: seqchoice})\n",
    "    #bcd2165_totalReads.to_csv('bcd2165_totalReads.csv',header = True)\n",
    "    matchedSeqs = bcd2165_totalReads['entire_read'].tolist()\n",
    "    choiceSeqs = bcd2165_totalReads[choiceSeqHeader].tolist()\n",
    "    return bcd2165_totalReads, matchedSeqs, choiceSeqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nth(haystack, needle, n):\n",
    "    start = haystack.find(needle)\n",
    "    while start >= 0 and n > 1:\n",
    "        start = haystack.find(needle, start+len(needle))\n",
    "        n -= 1\n",
    "    return start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writingFastQ(df, filename, header, reads):\n",
    "    fqlist = []\n",
    "    s = ''\n",
    "    r = ''\n",
    "    for i in range(0,len(df)):\n",
    "        s = '@'+str(df[header][i])+' '+'\\n'+df[reads][i]+'\\n'+'+'+'\\n'+('I'*len(df[reads][i]))+'\\n'\n",
    "        fqlist.append(s)\n",
    "    for j in fqlist:\n",
    "        r = r+j\n",
    "    writeFile(filename,r)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfBarcodeAln_new(d1, seqs, num, shortRead_len, typeBC): #have to adjust so for each, FWD, REV, and REDI options\n",
    "    reads = []\n",
    "    barcodeAln = []\n",
    "    barcodes = []\n",
    "    count = 0\n",
    "    headers = []\n",
    "    indexb4bcEND = []\n",
    "    r = 0\n",
    "    l = shortRead_len\n",
    "    for i in d1['indexb4bc']: \n",
    "        lengthConstantSeq = len(d1['sequences'][count])\n",
    "        if(len(seqs[count])>=num):\n",
    "            if(i-l <= 0):\n",
    "                reads.append(seqs[count][:i+lengthConstantSeq+l])\n",
    "                #if(count ==55):\n",
    "                    #print 'if than 650: ',count\n",
    "            elif(i+len(d1['sequences'][count])+l >= len(seqs[count])):\n",
    "                reads.append(seqs[count][i-l:])\n",
    "                #if(count ==55):\n",
    "                    #print 'elif than 650: ',count,i, 'total len', len(seqs[count])\n",
    "            else:\n",
    "                reads.append(seqs[count][i-l:i+lengthConstantSeq+l])\n",
    "                #if(count ==55):\n",
    "                    #print 'else than 650: ',count\n",
    "            #print 'greater', str(count)\n",
    "            \n",
    "        else:\n",
    "            reads.append(seqs[count][0:])\n",
    "            #print 'less', str(count)\n",
    "        if(typeBC == 'after'):    \n",
    "            barcodeAln.append(i-len(d1['sequences'][count]))\n",
    "        elif(typeBC=='before'):\n",
    "            barcodeAln.append(i+len(d1['sequences'][count]))\n",
    "        else: #REDI\n",
    "            barcodeAln.append(i-len(d1['sequences'][count]))\n",
    "        count = count + 1\n",
    "    d1['reads']=reads\n",
    "    d1[typeBC+'barcodeAln']=barcodeAln\n",
    "    #d1['barcode']=barcodes\n",
    "    #d1['headers'] = headers\n",
    "    return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ReadingFastQ-Copy1\n",
    "def readFastQ(filename):\n",
    "    sequences = []\n",
    "    qualities = []\n",
    "    with open(filename) as fh:\n",
    "        while True:\n",
    "            fh.readline()\n",
    "            seq = fh.readline().rstrip()\n",
    "            fh.readline()\n",
    "            qual = fh.readline().rstrip()\n",
    "            if len(seq) == 0:\n",
    "                break\n",
    "            sequences.append(seq)\n",
    "            qualities.append(qual)\n",
    "    return sequences, qualities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NewEverything\n",
    "def gettingReverseComplements(seqs, strands):\n",
    "    actualSeqs = []\n",
    "    for i in range(0, len(seqs)):\n",
    "        if strands[i] == '-':\n",
    "            seq = reverseComplement(seqs[i])\n",
    "        else:\n",
    "            seq = seqs[i]\n",
    "        actualSeqs.append(seq)\n",
    "    return actualSeqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TryingAlignmentTools.ipynb\n",
    "def alignment(large_string, query_string):\n",
    "    from Bio import pairwise2\n",
    "\n",
    "    from Bio.SubsMat import MatrixInfo as matlist\n",
    "    \n",
    "    matrix = matlist.blosum62\n",
    "    #print matrix\n",
    "    gap_open = -10\n",
    "\n",
    "    gap_extend = -0.5\n",
    "    # Only using the first 60 aas for visualization reasons..\n",
    "\n",
    "    #p53_human = \"MEEPQSDPSVEPPLSQETFSDLWKLLPENNVLSPLPSQAMDDLMLSPDDIEQWFTEDPGP\"\n",
    "\n",
    "    #p53_mouse = \"MEESQSDISLELPLSQETFSGLWKLLPPEDILPSPHCMDDLLLPQDVEEFFEGPSEALRV\"\n",
    "\n",
    "    alns = pairwise2.align.globalds(large_string, query_string, matrix, gap_open, gap_extend)\n",
    "\n",
    "    top_aln = alns[0]\n",
    "    #print alns\n",
    "    aln_large, aln_query, score, begin, end = top_aln\n",
    "    #print top_aln\n",
    "    string =  aln_large+'\\n'+aln_query\n",
    "    #print string\n",
    "    #print score, begin, end\n",
    "    return aln_large, aln_query, score, begin, end, string\n",
    "\n",
    "#TryingAlignmentTools.ipynb\n",
    "def gettingInfo(aln_large,aln_query, num):\n",
    "    #query_string = 'TAACCTCGGCA' \n",
    "    sList = aln_query.split('-')\n",
    "    l, m, i = maxLineLenList(sList)\n",
    "    begin = i+1\n",
    "    end = begin+l[i]\n",
    "    conSeq = aln_large[begin:end]\n",
    "    reads = aln_large[begin-num:end+num]\n",
    "    return begin, end, conSeq, reads\n",
    "\n",
    "#TryingAlignmentTools.ipynb\n",
    "def alignmentMultiple(large_strings100, query_string, num):\n",
    "    constantSequences = []\n",
    "    startpos = []\n",
    "    endpos = []\n",
    "    scores = []\n",
    "    reads = []\n",
    "    for i in large_strings100[0:2]:\n",
    "        large_string100 = i\n",
    "        #query_string = \"TAACCTCGGCA\"\n",
    "        aln_large, aln_query, score, begin, end, string = alignment(large_string100, query_string)\n",
    "        begin, end, conSeq, read = gettingInfo(aln_large,aln_query, num)\n",
    "        constantSequences.append(conSeq)\n",
    "        startpos.append(begin)\n",
    "        endpos.append(end)\n",
    "        scores.append(score)\n",
    "        reads.append(read)\n",
    "        print string\n",
    "        print score, '\\n', begin,'\\n',end, '\\n', conSeq\n",
    "        print '#####'\n",
    "    return constantSequences, startpos, endpos, scores, reads\n",
    "\n",
    "#TryingAlignmentTools.ipynb\n",
    "def gettingLenReads(large_strings, start, end, typeBC):\n",
    "    large_strings100 = []\n",
    "    for i in large_strings:\n",
    "        if typeBC == 'reverse':\n",
    "            j = i[-100:]\n",
    "        elif typeBC =='redi':\n",
    "            if end == 0:\n",
    "                j = i[start:]\n",
    "            else:\n",
    "                j = i[start:end]\n",
    "        else:\n",
    "            j = i[start:end]\n",
    "        large_strings100.append(j)\n",
    "    return large_strings100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createHistQuals(qualities):\n",
    "    hist = [0] * 100 #highest quality you can have \n",
    "    for qual in qualities:\n",
    "        for phred in qual:\n",
    "            q = phred33toQ(phred)\n",
    "            hist[q] +=1\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phred33toQ(qual):\n",
    "    return ord(qual) - 33\n",
    "def qualToPhred33(qual):\n",
    "    return chr(Q+33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "The function was called 49 times!\n"
     ]
    }
   ],
   "source": [
    "#levenshtein distance\n",
    "def call_counter(func):\n",
    "    def helper(*args, **kwargs):\n",
    "        helper.calls += 1\n",
    "        return func(*args, **kwargs)\n",
    "    helper.calls = 0\n",
    "    helper.__name__= func.__name__\n",
    "    return helper\n",
    "memo = {}\n",
    "@call_counter\n",
    "def levenshtein(s, t):\n",
    "    if s == \"\":\n",
    "        return len(t)\n",
    "    if t == \"\":\n",
    "        return len(s)\n",
    "    cost = 0 if s[-1] == t[-1] else 1\n",
    "       \n",
    "    i1 = (s[:-1], t)\n",
    "    if not i1 in memo:\n",
    "        memo[i1] = levenshtein(*i1)\n",
    "    i2 = (s, t[:-1])\n",
    "    if not i2 in memo:\n",
    "        memo[i2] = levenshtein(*i2)\n",
    "    i3 = (s[:-1], t[:-1])\n",
    "    if not i3 in memo:\n",
    "        memo[i3] = levenshtein(*i3)\n",
    "    res = min([memo[i1]+1, memo[i2]+1, memo[i3]+cost])\n",
    "    \n",
    "    return res\n",
    "#print(levenshtein(\"Python\", \"Pethno\"))\n",
    "#print(\"The function was called \" + str(levenshtein.calls) + \" times!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_levenshtein(s, t):\n",
    "    \"\"\" \n",
    "        iterative_levenshtein(s, t) -> ldist\n",
    "        ldist is the Levenshtein distance between the strings \n",
    "        s and t.\n",
    "        For all i and j, dist[i,j] will contain the Levenshtein \n",
    "        distance between the first i characters of s and the \n",
    "        first j characters of t\n",
    "    \"\"\"\n",
    "    rows = len(s)+1\n",
    "    cols = len(t)+1\n",
    "    dist = [[0 for x in range(cols)] for x in range(rows)]\n",
    "    # source prefixes can be transformed into empty strings \n",
    "    # by deletions:\n",
    "    for i in range(1, rows):\n",
    "        dist[i][0] = i\n",
    "    # target prefixes can be created from an empty source string\n",
    "    # by inserting the characters\n",
    "    for i in range(1, cols):\n",
    "        dist[0][i] = i\n",
    "        \n",
    "    for col in range(1, cols):\n",
    "        for row in range(1, rows):\n",
    "            if s[row-1] == t[col-1]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = 1\n",
    "            dist[row][col] = min(dist[row-1][col] + 1,      # deletion\n",
    "                                 dist[row][col-1] + 1,      # insertion\n",
    "                                 dist[row-1][col-1] + cost) # substitution\n",
    "    for r in range(rows):\n",
    "        print(dist[r])\n",
    "    \n",
    " \n",
    "    return dist[row][col]\n",
    "#print(iterative_levenshtein(\"flaw\", \"lawn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_levenshtein(s, t, costs=(1, 1, 1)):\n",
    "    \"\"\" \n",
    "        iterative_levenshtein(s, t) -> ldist\n",
    "        ldist is the Levenshtein distance between the strings \n",
    "        s and t.\n",
    "        For all i and j, dist[i,j] will contain the Levenshtein \n",
    "        distance between the first i characters of s and the \n",
    "        first j characters of t\n",
    "        \n",
    "        costs: a tuple or a list with three integers (d, i, s)\n",
    "               where d defines the costs for a deletion\n",
    "                     i defines the costs for an insertion and\n",
    "                     s defines the costs for a substitution\n",
    "    \"\"\"\n",
    "    rows = len(s)+1\n",
    "    cols = len(t)+1\n",
    "    deletes, inserts, substitutes = costs\n",
    "    \n",
    "    dist = [[0 for x in range(cols)] for x in range(rows)]\n",
    "    # source prefixes can be transformed into empty strings \n",
    "    # by deletions:\n",
    "    for row in range(1, rows):\n",
    "        dist[row][0] = row * deletes\n",
    "    # target prefixes can be created from an empty source string\n",
    "    # by inserting the characters\n",
    "    for col in range(1, cols):\n",
    "        dist[0][col] = col * inserts\n",
    "        \n",
    "    for col in range(1, cols):\n",
    "        for row in range(1, rows):\n",
    "            if s[row-1] == t[col-1]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = substitutes\n",
    "            dist[row][col] = min(dist[row-1][col] + deletes,\n",
    "                                 dist[row][col-1] + inserts,\n",
    "                                 dist[row-1][col-1] + cost) # substitution\n",
    "    for r in range(rows):\n",
    "        print(dist[r])\n",
    "    \n",
    " \n",
    "    return dist[row][col]\n",
    "# default:\n",
    "#print(iterative_levenshtein(\"abc\", \"xyz\"))\n",
    "# the costs for substitions are twice as high as inserts and delets:\n",
    "#print(iterative_levenshtein(\"abc\", \"xyz\", costs=(1, 1, 2)))\n",
    "# inserts and deletes are twice as high as substitutes\n",
    "#print(iterative_levenshtein(\"abc\", \"xyz\", costs=(2, 2, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
